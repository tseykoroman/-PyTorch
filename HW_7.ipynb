{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsumYjpHKYL+9NZdQJWi7Y"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание\n",
        "\n",
        "1. Попробуйте обучить нейронную сеть GRU/LSTM для предсказания сентимента сообщений с твитера на примере https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n",
        "\n",
        "2. Опишите, какой результат вы получили? Что помогло вам улучшить ее точность?"
      ],
      "metadata": {
        "id": "6g3lzhwufWqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YgK57m01fNQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dff0c9b-3ca1-4430-d543-a64ba4add3c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "2RNg5ZaJbYfe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "zkvquxp1bZtO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "xq1IoK56ba0O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download arkhoshghalb/twitter-sentiment-analysis-hatred-speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZjYVS9-bcOV",
        "outputId": "ded8c687-fbd1-40a0-bc18-3bd734d5d844"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading twitter-sentiment-analysis-hatred-speech.zip to /content\n",
            "100% 1.89M/1.89M [00:01<00:00, 2.13MB/s]\n",
            "100% 1.89M/1.89M [00:01<00:00, 1.87MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip twitter-sentiment-analysis-hatred-speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrUspyvvbfqV",
        "outputId": "63f9bc15-bc64-4c93-d156-1b1c0a5c7bd7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  twitter-sentiment-analysis-hatred-speech.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop-words pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W61UqOnbyII",
        "outputId": "7bce187f-5a70-4a1a-d057-8739dd1fcf16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stop-words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 23.6 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Building wheels for collected packages: stop-words, docopt\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32912 sha256=1228199606d7502d8afbeb06acf179593fc0c8754f08c0081deab089aa227ac1\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=5f2032703d5ffc181839647e003abbba8c63c23cd60d3f7a5119a40ba2a84a02\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "Successfully built stop-words docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, stop-words, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 stop-words-2018.7.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from tqdm import tqdm \n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "GFm2W_1Tbqu0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 2000\n",
        "max_len = 20\n",
        "num_classes = 1\n",
        "\n",
        "# Training\n",
        "epochs = 5\n",
        "batch_size = 512\n",
        "print_batch_n = 100"
      ],
      "metadata": {
        "id": "NFoWzeiZbh4G"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/train.csv')\n",
        "df_val = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "TcgI047OblQW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wF69cQwUbl1z",
        "outputId": "12c079a2-d881-49fe-99f0-fb26fd44584b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e388236e-8a2d-4a6a-9e32-596f41999028\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e388236e-8a2d-4a6a-9e32-596f41999028')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e388236e-8a2d-4a6a-9e32-596f41999028 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e388236e-8a2d-4a6a-9e32-596f41999028');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddXz9CLbblzf",
        "outputId": "3c26cea3-1ff2-47d6-f3b2-a2e32ac48c19"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29720\n",
              "1     2242\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train.drop('label', axis = 1)\n",
        "y = df_train['label']"
      ],
      "metadata": {
        "id": "0l0sAP7Iblw2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=13)"
      ],
      "metadata": {
        "id": "77Of6smlbluj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sw = set(get_stop_words(\"en\"))\n",
        "puncts = set(punctuation)"
      ],
      "metadata": {
        "id": "pWkAFgh9blsO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morpher = MorphAnalyzer()\n",
        "\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in puncts)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"не\\s\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)"
      ],
      "metadata": {
        "id": "x68nzOzXblp8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['tweet'].iloc[:1].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdKv1Dzrbln9",
        "outputId": "40506b3c-e5bc-489a-86d2-8fc606ce3e50"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['what is faith? â\\x96¸ + | #hope   #peace #justice #prosperity '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['tweet'].iloc[:1].apply(preprocess_text).values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw6OOFvRb7eE",
        "outputId": "52eb88ad-ee81-477a-c604-ff84d466371d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['faith â\\x96¸ hope peace justice prosperity'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas()\n",
        "\n",
        "X_train['tweet'] = X_train['tweet'].progress_apply(preprocess_text)\n",
        "X_val['tweet'] = X_val['tweet'].progress_apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AOILZTab7bI",
        "outputId": "c67b376a-9855-4644-a404-4ecc143d7ebc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28765/28765 [00:06<00:00, 4617.40it/s]\n",
            "100%|██████████| 3197/3197 [00:00<00:00, 4835.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = \" \".join(X_train[\"tweet\"])\n",
        "train_corpus = train_corpus.lower()"
      ],
      "metadata": {
        "id": "B0g-qMVbb7YX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "\n",
        "tokens = word_tokenize(train_corpus)\n",
        "tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-c_zBreb7Vn",
        "outputId": "5123f920-d5ad-4429-f4b4-4888505e30c4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['faith', 'â\\x96¸', 'hope', 'peace', 'justice']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered = [word for word in tokens if word.isalnum()]"
      ],
      "metadata": {
        "id": "WcMBTkeYb7TL"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n",
        "len(tokens_filtered_top)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D1vCt3xb7Qp",
        "outputId": "d21c57fd-6d5b-494d-9edf-8864e3962cbc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1999"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered_top[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BFjjQ91b7N4",
        "outputId": "9461330e-bcc0-4146-e10e-ded1f7fbd0f5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user', 'love', 'day', 'happy', 'amp', 'just', 'will', 'u', 'im', 'time']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
      ],
      "metadata": {
        "id": "j6sTmDabb7LW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "\n",
        "    padding = [0] * (maxlen-len(result))\n",
        "    return result[-maxlen:] + padding"
      ],
      "metadata": {
        "id": "PU_m1o9IcPBx"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X_train = np.asarray([text_to_sequence(text, max_len) for text in X_train['tweet']])\n",
        "X_val = np.asarray([text_to_sequence(text, max_len) for text in X_val['tweet']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOi20F56cO_f",
        "outputId": "107af8b3-d0b2-4c43-8643-9bb4026cde65"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.04 s, sys: 11.3 ms, total: 3.06 s\n",
            "Wall time: 3.07 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class LSTMFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, ht = self.lstm(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = lstm_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        # print(out.shape)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "9kDfUknccO89"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class DataWrapper(Dataset):\n",
        "    def __init__(self, data, target, transform=None):\n",
        "        self.data = torch.from_numpy(data).long()\n",
        "        self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "            \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "r7uXzEwJc7-h"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DataWrapper(X_train, y_train.values)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = DataWrapper(X_val, y_val.values)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "0HY5QKZsc8ki"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rf1L0J13c8iK",
        "outputId": "03209232-8b68-40c4-f0d8-966415df45c0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "HVcr3qPWdsLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_init = LSTMFixedLen(max_words, 128, 20, use_last=False)\n",
        "optimizer = torch.optim.Adam(lstm_init.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "f3JZcmr4c8fo"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lstm_init)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in lstm_init.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhPTLvFrcOw6",
        "outputId": "e44de8fa-cef4-4a9e-b487-1fe30450986a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMFixedLen(\n",
            "  (embeddings): Embedding(2000, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 20, num_layers=2, batch_first=True)\n",
            "  (linear): Linear(in_features=20, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Parameters: 271381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_init = lstm_init.to(device)\n",
        "lstm_init.train()\n",
        "th = 0.5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    lstm_init.train()\n",
        "    running_items, running_right = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = lstm_init(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "        running_items += len(labels)\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        running_right += (labels == pred_labels).sum()\n",
        "        \n",
        "    # выводим статистику о процессе обучения\n",
        "    lstm_init.eval()\n",
        "    \n",
        "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "            f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "            f'Loss: {loss:.3f}. ' \\\n",
        "            f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    train_loss_history.append(loss)\n",
        "\n",
        "    # выводим статистику на тестовых данных\n",
        "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "    for j, data in enumerate(val_loader):\n",
        "        test_labels = data[1].to(device)\n",
        "        test_outputs = lstm_init(data[0].to(device))\n",
        "        \n",
        "        # подсчет ошибки на тесте\n",
        "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "        # подсчет метрики на тесте\n",
        "        test_running_total += len(data[1])\n",
        "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "        test_running_right += (test_labels == pred_test_labels).sum()\n",
        "    \n",
        "    test_loss_history.append(test_loss.item())\n",
        "    print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}')\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5AJ18LJcOuf",
        "outputId": "4f482021-83c4-4ee6-e371-a97fb394563e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [57/57]. Loss: 0.193. Acc: 0.698. Test loss: 0.505. Test acc: 0.933\n",
            "Epoch [2/5]. Step [57/57]. Loss: 0.122. Acc: 0.929. Test loss: 0.069. Test acc: 0.933\n",
            "Epoch [3/5]. Step [57/57]. Loss: 0.192. Acc: 0.929. Test loss: 0.070. Test acc: 0.933\n",
            "Epoch [4/5]. Step [57/57]. Loss: 0.143. Acc: 0.937. Test loss: 0.036. Test acc: 0.941\n",
            "Epoch [5/5]. Step [57/57]. Loss: 0.108. Acc: 0.948. Test loss: 0.208. Test acc: 0.946\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU"
      ],
      "metadata": {
        "id": "Ll-W0o5AdpO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class GRUFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU( embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        gru_out, ht = self.gru(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = gru_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "6FSG8iP3cOpg"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_init = GRUFixedLen(max_words, 128, 20, use_last=False)\n",
        "optimizer = torch.optim.Adam(gru_init.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "slOSCS7idcxs"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gru_init)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in gru_init.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr3a6vcsdcvM",
        "outputId": "a83f4f51-06bb-4657-f7f5-23935d969bc9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRUFixedLen(\n",
            "  (embeddings): Embedding(2000, 128, padding_idx=0)\n",
            "  (gru): GRU(128, 20, num_layers=2, batch_first=True)\n",
            "  (linear): Linear(in_features=20, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Parameters: 267541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_init = gru_init.to(device)\n",
        "gru_init.train()\n",
        "th = 0.5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs): \n",
        "    gru_init.train() \n",
        "    running_items, running_right = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = gru_init(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "        running_items += len(labels)\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        running_right += (labels == pred_labels).sum()\n",
        "        \n",
        "    # выводим статистику о процессе обучения\n",
        "    gru_init.eval()\n",
        "    \n",
        "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "          f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "          f'Loss: {loss:.3f}. ' \\\n",
        "          f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    train_loss_history.append(loss)\n",
        "\n",
        "    # выводим статистику на тестовых данных\n",
        "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "    for j, data in enumerate(val_loader):\n",
        "        test_labels = data[1].to(device)\n",
        "        test_outputs = gru_init(data[0].to(device))\n",
        "        \n",
        "        # подсчет ошибки на тесте\n",
        "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "        # подсчет метрики на тесте\n",
        "        test_running_total += len(data[1])\n",
        "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "        test_running_right += (test_labels == pred_test_labels).sum()\n",
        "    \n",
        "    test_loss_history.append(test_loss.item())\n",
        "    print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}')\n",
        "            \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSvXF3Nfdcsj",
        "outputId": "daf2a482-4739-4f30-aa6c-63bc1fb013cf"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [57/57]. Loss: 0.340. Acc: 0.926. Test loss: 0.115. Test acc: 0.933\n",
            "Epoch [2/5]. Step [57/57]. Loss: 0.235. Acc: 0.929. Test loss: 0.070. Test acc: 0.933\n",
            "Epoch [3/5]. Step [57/57]. Loss: 0.188. Acc: 0.932. Test loss: 0.049. Test acc: 0.936\n",
            "Epoch [4/5]. Step [57/57]. Loss: 0.147. Acc: 0.943. Test loss: 0.339. Test acc: 0.946\n",
            "Epoch [5/5]. Step [57/57]. Loss: 0.101. Acc: 0.949. Test loss: 0.022. Test acc: 0.949\n",
            "Training is finished!\n"
          ]
        }
      ]
    }
  ]
}